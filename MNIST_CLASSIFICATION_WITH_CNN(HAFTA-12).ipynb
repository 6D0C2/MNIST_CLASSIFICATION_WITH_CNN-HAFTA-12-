{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca867528-6c84-4a7a-861e-fb630764f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd7508f-34ea-4ee8-b290-e180e7727695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# MNIST veri setinin Keras kütüphanesi üzerinden yüklenmesi\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934de587-effb-463a-8813-a04a5f45ef2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitim (Train) Verilerinin Sayısı ve boyutu = (60000, 28, 28, 1)\n",
      "Test verilerinin sayısı ve Boyutu = (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Veri Ön İşleme - Adım 1 - Görüntülerin yeniden boyutlandırılması\n",
    "\n",
    "x_train = x_train.reshape(-1, 28, 28, 1) # -1: Görüntülerin toplam sayısı\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "#Veri Ön İşleme - Adım 2 - Görüntülerin normalize edilmesi# -1: Görüntülerin toplam sayısı\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "print(f\"Eğitim (Train) Verilerinin Sayısı ve boyutu = {x_train.shape}\")\n",
    "print(f\"Test verilerinin sayısı ve Boyutu = {x_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6fdf265-675c-41fc-9337-5487a49d53db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x199fb945ff0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Çıkış verisi olarak bu gıral görüntülerini hangi rakamı temsil ettiğini gösteren y verilerini düzeliyoruz\n",
    "\n",
    "plt.imshow(x_train[50000],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "686f9208-ef85-453c-890a-f2cf0bcc52a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c5a693-3339-4f9d-9090-f9930c85d187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot Encoding\n",
    "y_train = keras.utils.to_categorical(y_train,10)\n",
    "y_test = keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b416557a-07e6-407f-9e05-20cf07cbcbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30f9d45d-fea2-49a2-90c8-f582318c2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eğitim verilerinin %20'sinin doğrulama (validation) verisi olarak ayrılması Literatürde Data-split işlemi denilir.\n",
    "# bu işlem genellikle sklear altındaki train_test_split fonksiyonu ile yapılır\n",
    "\n",
    "X_train, X_val, y_train_split, y_val = train_test_split(\n",
    "    x_train, y_train,\n",
    "    test_size = 0.2, #validasyon verisi yüzde kaç olacak bilgisi burada\n",
    "    random_state = 42, # rastgelelik işlemini biraz sınırlı tutuyoruz\n",
    "    stratify = y_train # rastgele şekilde dağılım yaparken sınıf dengesini korur\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb3e3ed6-f276-41cc-98bc-92801a17fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN tabanlı yapayzeka modelimizi oluşturuyoruz\n",
    "model = keras.Sequential([\n",
    "    #CNN ilk blok\n",
    "    keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape =(28,28,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Dropout(0.25),\n",
    "\n",
    "    #CNN ikinci blok\n",
    "    keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Dropout(0.25),\n",
    "\n",
    "    #YAPAY SİNİR AĞI TANIMLIYORUZ\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512,activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation = 'softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6da2471e-317a-4935-a7da-4b2c8480f06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeli derliyoruz\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss = 'categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "722139e2-03f6-4135-8ae0-7d5867a63f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'mnist_classifiction_cnn_model_h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11f6ead6-442f-43a4-8354-c51c863769d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.2013 - accuracy: 0.9396\n",
      "Epoch 1: val_accuracy improved from -inf to 0.15367, saving model to mnist_classifiction_cnn_model_h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 66s 173ms/step - loss: 0.2013 - accuracy: 0.9396 - val_loss: 5.5589 - val_accuracy: 0.1537\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0667 - accuracy: 0.9790\n",
      "Epoch 2: val_accuracy improved from 0.15367 to 0.98433, saving model to mnist_classifiction_cnn_model_h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 64s 170ms/step - loss: 0.0667 - accuracy: 0.9790 - val_loss: 0.0493 - val_accuracy: 0.9843\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9846\n",
      "Epoch 3: val_accuracy improved from 0.98433 to 0.98842, saving model to mnist_classifiction_cnn_model_h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 66s 176ms/step - loss: 0.0488 - accuracy: 0.9846 - val_loss: 0.0363 - val_accuracy: 0.9884\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9871\n",
      "Epoch 4: val_accuracy improved from 0.98842 to 0.99108, saving model to mnist_classifiction_cnn_model_h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 63s 168ms/step - loss: 0.0399 - accuracy: 0.9871 - val_loss: 0.0288 - val_accuracy: 0.9911\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9890\n",
      "Epoch 5: val_accuracy improved from 0.99108 to 0.99158, saving model to mnist_classifiction_cnn_model_h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 60s 159ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 0.0299 - val_accuracy: 0.9916\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9900\n",
      "Epoch 6: val_accuracy improved from 0.99158 to 0.99192, saving model to mnist_classifiction_cnn_model_h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 95s 255ms/step - loss: 0.0311 - accuracy: 0.9900 - val_loss: 0.0287 - val_accuracy: 0.9919\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0275 - accuracy: 0.9912\n",
      "Epoch 7: val_accuracy improved from 0.99192 to 0.99275, saving model to mnist_classifiction_cnn_model_h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 103s 274ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.0241 - val_accuracy: 0.9927\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0268 - accuracy: 0.9911\n",
      "Epoch 8: val_accuracy did not improve from 0.99275\n",
      "375/375 [==============================] - 97s 260ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 0.0247 - val_accuracy: 0.9925\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0253 - accuracy: 0.9915\n",
      "Epoch 9: val_accuracy improved from 0.99275 to 0.99283, saving model to mnist_classifiction_cnn_model_h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 104s 277ms/step - loss: 0.0253 - accuracy: 0.9915 - val_loss: 0.0297 - val_accuracy: 0.9928\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9930\n",
      "Epoch 10: val_accuracy improved from 0.99283 to 0.99333, saving model to mnist_classifiction_cnn_model_h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_classifiction_cnn_model_h5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 100s 268ms/step - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0241 - val_accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "#Modelimizi eğitiyoruz(.fit fonksiyonu ile)\n",
    "\n",
    "history = model.fit(X_train, y_train_split, validation_data=(X_val, y_val),\n",
    "                  batch_size=128, epochs=10,  callbacks=model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6d3dd41-19bc-4040-890b-2973cb2b5056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test işlemi için değerşnedirme yapılıyor\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.0183 - accuracy: 0.9933\n",
      "Modelin Loss performansı = 0.018258394673466682\n",
      "Modelin Accuracy (Doğruluk Başarısı) Performansı = 0.9933000206947327\n"
     ]
    }
   ],
   "source": [
    "print(\"Test işlemi için değerşnedirme yapılıyor\")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f\"Modelin Loss performansı = {test_loss}\")\n",
    "print(f\"Modelin Accuracy (Doğruluk Başarısı) Performansı = {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65130783-9c8e-413f-8d11-56f3e3b5d5c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_bst",
   "language": "python",
   "name": "env_bst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
